# ==========================================================================================
# NGINX Otimizado para Benchmark de Alta Concorrência com Recursos Limitados
# Foco: Alto throughput (RPS) de pequenas requisições HTTP/1.1
# ==========================================================================================

# A diretiva 'auto' é ideal. Dado o limite de 0.2 CPU, o Nginx provavelmente usará 1 worker.
worker_processes auto;

# Define o limite de arquivos abertos para os workers. Deve ser maior que worker_connections.
# Garante que o Nginx não ficará sem descritores de arquivo sob carga.
worker_rlimit_nofile 4096;

# Desativa logs de erro para remover I/O de disco. Esta diretiva é permitida no contexto principal.
error_log /dev/null;

events {
    # Número de conexões por worker. Reduzido para um valor realista para 0.2 CPU e 50MB de RAM.
    worker_connections 2048;

    # Otimização para Linux: usa a forma mais eficiente de notificação de I/O.
    use epoll;

    # Permite que um worker aceite múltiplas conexões de uma vez, reduzindo a latência sob carga.
    multi_accept on;
}

http {
    # CORREÇÃO: Movido 'access_log off' para dentro do contexto 'http', onde é permitido.
    # Desativa completamente o log de acesso para economizar I/O de disco e CPU.
    access_log off;

    # Inclui tipos MIME básicos para o Nginx entender os formatos de arquivo.
    include /etc/nginx/mime.types;

    # Otimizações de TCP/IP para máxima eficiência e baixa latência.
    tcp_nopush on; # Envia cabeçalhos e início do corpo em um único pacote.
    tcp_nodelay on; # Envia dados imediatamente, sem aguardar para preencher o buffer.

    # Define um timeout para as conexões keep-alive com o cliente.
    keepalive_timeout 65s;

    # Libera a memória de conexões que atingiram timeout de forma mais agressiva.
    reset_timedout_connection on;

    # Define o upstream (grupo de servidores backend).
    upstream api_backend {
        server app1:3001;
        server app2:3002;

        # Mantém um cache de 300 conexões abertas e ociosas para cada worker
        # com os servidores de backend, eliminando o custo do handshake TCP.
        keepalive 300;
    }

    server {
        listen 9999;

        location / {
            # Habilita o buffering. O Nginx lê a resposta inteira da API
            # e libera a conexão com o backend imediatamente. Essencial para alto throughput.
            proxy_buffering on;

            # Habilita o uso de HTTP/1.1 e do pool de keepalive definido no upstream.
            proxy_http_version 1.1;
            proxy_set_header Connection ""; # Garante o reuso da conexão keep-alive.

            # Encaminha a requisição para o grupo de servidores.
            proxy_pass http://api_backend;
        }
    }
}